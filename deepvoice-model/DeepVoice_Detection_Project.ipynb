{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2xS__SMKVUo",
        "outputId": "011ad891-02d4-48a1-c9d2-cdbe8c3d703b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBc5YvfQWkc8",
        "outputId": "aa00dc7c-dbf4-4342-fad6-09532c2bcbc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoyJzNKKKfkc"
      },
      "outputs": [],
      "source": [
        "base_path = '/content/drive/MyDrive/Deepvoice_Detection_Dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAb2MzkysPKw",
        "outputId": "d9f43706-5ab4-4596-ea45-4c6a37e5d9d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ASVspoof2019.LA.cm.dev.trl.txt\t ASVspoof2019.LA.cm.train.trn.txt\n",
            "ASVspoof2019.LA.cm.eval.trl.txt\n",
            "LA_T_1000137.flac\n",
            "LA_T_1000406.flac\n",
            "LA_T_1000648.flac\n",
            "LA_T_1000824.flac\n",
            "LA_T_1001074.flac\n",
            "LA_T_1001114.flac\n",
            "LA_T_1001169.flac\n",
            "LA_T_1001718.flac\n",
            "LA_T_1001871.flac\n",
            "LA_T_1002656.flac\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Deepvoice_Detection_Dataset/ASVspoof2019_LA_cm_protocols/\n",
        "!ls /content/drive/MyDrive/Deepvoice_Detection_Dataset/flac | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmaiWG-SiCZC"
      },
      "outputs": [],
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì •ë¦¬\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import glob\n",
        "import torchaudio\n",
        "import random\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dH-q6Yf8czQb"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iylbbXyUcBf"
      },
      "outputs": [],
      "source": [
        "# Step 0. ë°ì´í„° ë¶„ì„ ë° ì²˜ë¦¬\n",
        "# 1. Train ë°ì´í„°ì…‹ê³¼ Eval ë°ì´í„°ì…‹ í•©ì¹˜ê¸°\n",
        "\n",
        "# 2. í•©ì¹œ ë°ì´í„°ì…‹ì—ì„œ 8:2 ë¹„ìœ¨ë¡œ ë‚˜ëˆ„ê¸°\n",
        "\n",
        "# 3. 8ì€ í•™ìŠµì— ì‚¬ìš©í•˜ê³  2ëŠ” í‰ê°€ì— ì‚¬ìš©í•˜ê¸° (train, test)\n",
        "\n",
        "# í”„ë¡œí† ì½œ ê²½ë¡œ\n",
        "train_protocol_path = os.path.join(base_path, 'ASVspoof2019_LA_cm_protocols', 'ASVspoof2019.LA.cm.train.trn.txt')\n",
        "eval_protocol_path = os.path.join(base_path, 'ASVspoof2019_LA_cm_protocols', 'ASVspoof2019.LA.cm.eval.trl.txt')\n",
        "\n",
        "# í”„ë¡œí† ì½œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "columns = ['speaker_id', 'file_id', 'system_id', 'attack_type', 'label']\n",
        "df_train = pd.read_csv(train_protocol_path, sep='\\s+', header=None, names=columns)\n",
        "df_eval = pd.read_csv(eval_protocol_path, sep='\\s+', header=None, names=columns)\n",
        "\n",
        "# ë³‘í•©\n",
        "df_all = pd.concat([df_train, df_eval], ignore_index=True)\n",
        "\n",
        "# stratified 8:2 ë¶„í• \n",
        "train_set, test_set = train_test_split(\n",
        "    df_all,\n",
        "    test_size=0.2,\n",
        "    stratify=df_all['label'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ê²°ê³¼ ì €ì¥\n",
        "train_output = os.path.join(base_path, 'ASVspoof2019_LA_cm_protocols', 'custom_protocol_train.txt')\n",
        "test_output = os.path.join(base_path, 'ASVspoof2019_LA_cm_protocols', 'custom_protocol_test.txt')\n",
        "\n",
        "train_set.to_csv(train_output, sep=' ', header=False, index=False)\n",
        "test_set.to_csv(test_output, sep=' ', header=False, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0AJDYFrKhnm"
      },
      "outputs": [],
      "source": [
        "# Step 1. custom_protocol_train.txt ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "\n",
        "# ì‚¬ìš©ì ì •ì˜ protocol ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "train_df = pd.read_csv(train_output, sep='\\s+', header=None, names=['speaker_id', 'file_id', 'system_id', 'attack_type', 'label'])\n",
        "\n",
        "# ë¼ë²¨ ìˆ«ìë¡œ ë³€í™˜\n",
        "train_df['label_binary'] = train_df['label'].map({'bonafide': 0, 'spoof': 1})\n",
        "\n",
        "# ê²½ë¡œ ì„¤ì • (train + eval ëª¨ë‘ ëŒ€ìƒì´ë¯€ë¡œ ë‘ ê²½ë¡œ ì„¤ì •)\n",
        "flac_dirs = [\n",
        "    '/content/drive/MyDrive/Deepvoice_Detection_Dataset/flac',\n",
        "    '/content/drive/MyDrive/Deepvoice_Detection_Dataset/ASVspoof2019_LA_eval/flac'\n",
        "]\n",
        "\n",
        "def find_flac_path(file_id):\n",
        "    for base in flac_dirs:\n",
        "        full_path = os.path.join(base, file_id + '.flac')\n",
        "        if os.path.exists(full_path):\n",
        "            return full_path\n",
        "    return None\n",
        "\n",
        "train_df['file_path'] = train_df['file_id'].apply(find_flac_path)\n",
        "train_df = train_df[train_df['file_path'].notnull()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcx_7QhhLC6m"
      },
      "outputs": [],
      "source": [
        "# Step 2. ë°ì´í„° ì „ì²˜ë¦¬\n",
        "# > ë°ì´í„° ì¦ê°•\n",
        "# > bonafideë§Œ ì¦ê°•í•´ì„œ mel ë³€í™˜, spoofëŠ” ê·¸ëŒ€ë¡œ mel ë³€í™˜\n",
        "\n",
        "def augment_waveform(path):\n",
        "    waveform, sr = torchaudio.load(path)\n",
        "\n",
        "    if random.random() < 0.5:\n",
        "        speed = random.choice([0.9, 1.1])\n",
        "        new_sr = int(sr * speed)\n",
        "        waveform = torchaudio.functional.resample(waveform, sr, new_sr)\n",
        "        waveform = torchaudio.functional.resample(waveform, new_sr, sr)\n",
        "\n",
        "    if random.random() < 0.5:\n",
        "        noise = 0.005 * torch.randn_like(waveform)\n",
        "        waveform += noise\n",
        "\n",
        "    return waveform\n",
        "\n",
        "def extract_mel_from_waveform(waveform, sr=16000, n_mels=80, fixed_length=400):\n",
        "    mel = torchaudio.transforms.MelSpectrogram(sample_rate=sr, n_mels=n_mels)(waveform)\n",
        "    mel_db = torchaudio.transforms.AmplitudeToDB()(mel)\n",
        "    mel_np = mel_db.squeeze(0).numpy()\n",
        "\n",
        "    # Padding or Trimming\n",
        "    if mel_np.shape[1] < fixed_length:\n",
        "        pad_width = fixed_length - mel_np.shape[1]\n",
        "        mel_np = np.pad(mel_np, ((0, 0), (0, pad_width)), mode='constant')\n",
        "    else:\n",
        "        mel_np = mel_np[:, :fixed_length]\n",
        "\n",
        "    # âœ… z-score ì •ê·œí™”\n",
        "    mel_np = (mel_np - mel_np.mean()) / (mel_np.std() + 1e-6)\n",
        "\n",
        "    return mel_np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s464zgueLK7f",
        "outputId": "2bd4a7ed-76b4-4009-d0cd-b56f471c9ecf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:   3%|â–         | 2011/77293 [00:34<4:22:26,  4.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 0 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_0.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:   5%|â–Œ         | 4003/77293 [01:14<5:50:40,  3.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 1 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_1.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:   8%|â–Š         | 6011/77293 [01:57<4:00:07,  4.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 2 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_2.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  10%|â–ˆ         | 8008/77293 [02:37<3:39:56,  5.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 3 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_3.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  13%|â–ˆâ–        | 10009/77293 [03:17<3:32:21,  5.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 4 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_4.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  16%|â–ˆâ–Œ        | 12008/77293 [03:59<3:34:50,  5.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 5 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_5.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  18%|â–ˆâ–Š        | 14000/77293 [09:53<43:19:12,  2.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 6 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_6.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  21%|â–ˆâ–ˆ        | 16000/77293 [18:35<42:24:23,  2.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 7 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_7.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  23%|â–ˆâ–ˆâ–       | 18000/77293 [27:07<41:08:45,  2.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 8 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_8.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  26%|â–ˆâ–ˆâ–Œ       | 20000/77293 [35:42<40:00:14,  2.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 9 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_9.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  28%|â–ˆâ–ˆâ–Š       | 22000/77293 [44:21<37:26:55,  2.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 10 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_10.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  31%|â–ˆâ–ˆâ–ˆ       | 24000/77293 [53:05<36:11:55,  2.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 11 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_11.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  34%|â–ˆâ–ˆâ–ˆâ–      | 26001/77293 [1:02:20<25:21:04,  1.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 12 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_12.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 28000/77293 [1:11:03<33:54:22,  2.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 13 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_13.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 30000/77293 [1:19:44<32:55:23,  2.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 14 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_14.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32000/77293 [1:28:17<31:52:34,  2.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 15 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_15.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34000/77293 [1:36:50<29:41:26,  2.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 16 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_16.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 36000/77293 [1:45:28<28:43:14,  2.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 17 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_17.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 38000/77293 [1:54:11<27:01:13,  2.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 18 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_18.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40000/77293 [2:02:52<25:40:32,  2.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 19 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_19.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 42000/77293 [2:11:24<30:32:02,  3.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 20 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_20.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 44000/77293 [2:20:00<22:23:56,  2.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 21 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_21.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 46000/77293 [2:28:33<21:57:17,  2.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 22 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_22.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48000/77293 [2:37:24<19:08:48,  2.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 23 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_23.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50000/77293 [2:46:03<18:46:52,  2.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 24 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_24.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 52000/77293 [2:54:40<17:55:56,  2.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 25 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_25.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 54000/77293 [3:03:14<15:10:30,  2.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 26 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_26.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56000/77293 [3:11:39<14:20:23,  2.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 27 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_27.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 58000/77293 [3:20:08<13:15:20,  2.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 28 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_28.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 60000/77293 [3:28:36<12:03:53,  2.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 29 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_29.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 62000/77293 [3:37:05<10:25:39,  2.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 30 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_30.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 64000/77293 [3:45:35<9:23:02,  2.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 31 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_31.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 66000/77293 [3:54:02<7:35:48,  2.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 32 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_32.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 68000/77293 [4:02:29<6:41:01,  2.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 33 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_33.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 70000/77293 [4:10:59<5:00:12,  2.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 34 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_34.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 72000/77293 [4:19:26<3:33:14,  2.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 35 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_35.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 74000/77293 [4:27:55<2:14:36,  2.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 36 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_36.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 76000/77293 [4:36:21<53:52,  2.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì €ì¥ ì™„ë£Œ: batch 37 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_37.npy (2000ê°œ ìƒ˜í”Œ)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ”„ train mel ìƒì„±: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77293/77293 [4:41:49<00:00,  4.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ë§ˆì§€ë§‰ ì €ì¥ ì™„ë£Œ: batch 38 â†’ /content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug/train_data_batch_38.npy (1293ê°œ ìƒ˜í”Œ)\n"
          ]
        }
      ],
      "source": [
        "# Step 3. ë°ì´í„° ì „ì²˜ë¦¬\n",
        "# > Mel-spectrogram ë³€í™˜ ë° ì €ì¥\n",
        "\n",
        "mel_list, label_list = [], []\n",
        "batch_size = 2000\n",
        "batch_idx = 0\n",
        "save_dir = '/content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"ğŸ”„ train mel ìƒì„±\"):\n",
        "    try:\n",
        "        path = row['file_path']\n",
        "        label = row['label_binary']\n",
        "\n",
        "        if label == 0:  # bonafide â†’ ì¦ê°•\n",
        "            waveform = augment_waveform(path)\n",
        "        else:\n",
        "            waveform, _ = torchaudio.load(path)\n",
        "\n",
        "        mel = extract_mel_from_waveform(waveform)\n",
        "        mel_list.append(mel)\n",
        "        label_list.append(label)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ {path}: {e}\")\n",
        "        continue\n",
        "\n",
        "    if len(mel_list) >= batch_size:\n",
        "      data_path = os.path.join(save_dir, f'train_data_batch_{batch_idx}.npy')\n",
        "      label_path = os.path.join(save_dir, f'train_labels_batch_{batch_idx}.npy')\n",
        "\n",
        "      np.save(data_path, np.stack(mel_list))\n",
        "      np.save(label_path, np.array(label_list))\n",
        "\n",
        "      print(f\"âœ… ì €ì¥ ì™„ë£Œ: batch {batch_idx} â†’ {data_path} ({len(mel_list)}ê°œ ìƒ˜í”Œ)\")\n",
        "\n",
        "      mel_list, label_list = [], []\n",
        "      batch_idx += 1\n",
        "\n",
        "\n",
        "# ë§ˆì§€ë§‰ ì €ì¥\n",
        "if mel_list:\n",
        "    data_path = os.path.join(save_dir, f'train_data_batch_{batch_idx}.npy')\n",
        "    label_path = os.path.join(save_dir, f'train_labels_batch_{batch_idx}.npy')\n",
        "\n",
        "    np.save(data_path, np.stack(mel_list))\n",
        "    np.save(label_path, np.array(label_list))\n",
        "\n",
        "    print(f\"âœ… ë§ˆì§€ë§‰ ì €ì¥ ì™„ë£Œ: batch {batch_idx} â†’ {data_path} ({len(mel_list)}ê°œ ìƒ˜í”Œ)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpneFry0FUfC"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "\n",
        "class LazyMelDataset(Dataset):\n",
        "    def __init__(self, data_dir, prefix='train'):\n",
        "        self.data_dir = data_dir\n",
        "        self.prefix = prefix\n",
        "        self.data_paths = sorted([\n",
        "            os.path.join(data_dir, f) for f in os.listdir(data_dir)\n",
        "            if f.startswith(f'{self.prefix}_data')\n",
        "        ])\n",
        "        self.label_paths = sorted([\n",
        "            os.path.join(data_dir, f) for f in os.listdir(data_dir)\n",
        "            if f.startswith(f'{self.prefix}_labels')\n",
        "        ])\n",
        "        self.index_map = self._create_index_map()\n",
        "\n",
        "    def _create_index_map(self):\n",
        "        index_map = []\n",
        "        for batch_idx, data_path in enumerate(self.data_paths):\n",
        "            data = np.load(data_path, mmap_mode='r')\n",
        "            if len(data) == 0:\n",
        "                print(f\"âš ï¸ Skipping empty batch: {data_path}\")\n",
        "                continue\n",
        "            for i in range(len(data)):\n",
        "                index_map.append((batch_idx, i))\n",
        "        return index_map\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_idx, item_idx = self.index_map[idx]\n",
        "        mel = np.load(self.data_paths[batch_idx], mmap_mode='r')[item_idx]\n",
        "        label = np.load(self.label_paths[batch_idx], mmap_mode='r')[item_idx]\n",
        "        mel_tensor = torch.tensor(mel, dtype=torch.float32).unsqueeze(0)\n",
        "        label_tensor = torch.tensor(label, dtype=torch.float32)\n",
        "        return mel_tensor, label_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUBmMtnsIDjj"
      },
      "outputs": [],
      "source": [
        "# í•™ìŠµ ëª¨ë¸ ì •ì˜\n",
        "# CNN + Bi-GRU + Attention\n",
        "\n",
        "# Attention ë¸”ë¡ ì •ì˜\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.query = nn.Linear(input_dim, input_dim)\n",
        "        self.key = nn.Linear(input_dim, input_dim)\n",
        "        self.value = nn.Linear(input_dim, input_dim)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):  # x: (B, T, D)\n",
        "        Q = self.query(x)\n",
        "        K = self.key(x)\n",
        "        V = self.value(x)\n",
        "        attn_weights = self.softmax(torch.bmm(Q, K.transpose(1, 2)) / (Q.size(-1) ** 0.5))\n",
        "        out = torch.bmm(attn_weights, V)  # (B, T, D)\n",
        "        return out.mean(dim=1)  # (B, D)\n",
        "\n",
        "# DeepVoiceDetector with automatic GRU input size inference\n",
        "class DeepVoiceDetector(nn.Module):\n",
        "    def __init__(self, input_channels=1, hidden_size=128, sample_input_shape=(1, 400, 80)):\n",
        "        super(DeepVoiceDetector, self).__init__()\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        # GRU ì…ë ¥ í¬ê¸° ìë™ ì¶”ë¡ \n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros((1, input_channels, *sample_input_shape[1:]))  # (1, 1, 400, 80)\n",
        "            cnn_out = self.cnn(dummy_input)  # (1, 128, T', F') ì˜ˆìƒ\n",
        "            print(\"CNN output shape:\", cnn_out.shape)\n",
        "            _, c, t, f = cnn_out.shape\n",
        "            self.rnn_input_dim = c * f\n",
        "            self.rnn_time_steps = t\n",
        "\n",
        "        self.gru = nn.GRU(input_size=self.rnn_input_dim, hidden_size=hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.attn = Attention(input_dim=hidden_size * 2)\n",
        "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
        "\n",
        "    def forward(self, x):  # x: (B, 1, 400, 80)\n",
        "      batch_size = x.size(0)\n",
        "      x = self.cnn(x)                    # (B, 128, 50, 10)\n",
        "      x = self.dropout(x)\n",
        "      x = x.permute(0, 2, 1, 3)          # (B, 50, 128, 10)\n",
        "      x = x.reshape(batch_size, 50, -1)  # (B, 50, 1280)\n",
        "      out, _ = self.gru(x)               # (B, 50, 256)\n",
        "      out = self.attn(out)               # (B, 256)\n",
        "      out = self.fc(out).squeeze(1)      # (B,)\n",
        "      return out\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdU_NbD3FO9m"
      },
      "outputs": [],
      "source": [
        "# DataLoader ì •ì˜í•˜ê¸°\n",
        "\n",
        "dataset = LazyMelDataset('/content/drive/MyDrive/Deepvoice_Detection_Dataset/train_aug')\n",
        "\n",
        "train_len = int(0.8 * len(dataset))\n",
        "val_len = len(dataset) - train_len\n",
        "train_dataset, val_dataset = random_split(dataset, [train_len, val_len])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aAdWR-dFgJc",
        "outputId": "dabc1ea0-ba99-40e2-97e6-fb5b5952c165"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN output shape: torch.Size([1, 128, 50, 10])\n"
          ]
        }
      ],
      "source": [
        "# ëª¨ë¸ ì„ ì–¸ ë° í•™ìŠµ í™˜ê²½ êµ¬ì„±\n",
        "\n",
        "model = model = DeepVoiceDetector(input_channels=1, hidden_size=128, sample_input_shape=(1, 400, 80)).to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwNYibNXH5kk"
      },
      "outputs": [],
      "source": [
        "def compute_f1(preds, targets, threshold=0.5):\n",
        "    pred_labels = (np.array(preds) > threshold).astype(int)\n",
        "    return f1_score(targets, pred_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrOdDDL7HEpf",
        "outputId": "10fa5455-d721-4a3e-b092-54a59c58c631"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¥ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì¤‘...\n",
            "ğŸ” 13 epochë¶€í„° ì¬ì‹œì‘ (ìµœê³  F1: 0.9998)\n",
            "\n",
            "ğŸ” Epoch 14/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Epoch 14 | Train Loss: 0.0023 | Val Loss: 0.0001 | F1-score: 1.0000\n",
            "âœ… ëª¨ë¸ ì €ì¥ë¨ (F1 ê°±ì‹ : 1.0000)\n",
            "\n",
            "ğŸ” Epoch 15/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Epoch 15 | Train Loss: 0.0018 | Val Loss: 0.0009 | F1-score: 0.9997\n",
            "\n",
            "ğŸ” Epoch 16/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Epoch 16 | Train Loss: 0.0025 | Val Loss: 0.0015 | F1-score: 0.9998\n",
            "\n",
            "ğŸ” Epoch 17/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ğŸ”§ Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 708/1933 [46:45<1:21:52,  4.01s/it, loss=0.0574]"
          ]
        }
      ],
      "source": [
        "# Step 4. ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "best_f1 = 0.0\n",
        "EPOCHS = 20\n",
        "\n",
        "checkpoint_path = os.path.join(base_path, 'deepvoice_checkpoint.pt')\n",
        "start_epoch = 0\n",
        "best_f1 = 0.0\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(\"ğŸ“¥ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì¤‘...\")\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    best_f1 = checkpoint['best_f1']\n",
        "    print(f\"ğŸ” {start_epoch} epochë¶€í„° ì¬ì‹œì‘ (ìµœê³  F1: {best_f1:.4f})\")\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    print(f\"\\nğŸ” Epoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_bar = tqdm(train_loader, desc=\"ğŸ”§ Training\", leave=False)\n",
        "    for mel, label in train_bar:\n",
        "        mel, label = mel.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(mel)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * mel.size(0)\n",
        "        train_bar.set_postfix(loss=loss.item())\n",
        "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    preds, targets = [], []\n",
        "    val_bar = tqdm(val_loader, desc=\"ğŸ§ª Validation\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for mel, label in val_bar:\n",
        "            mel, label = mel.to(device), label.to(device)\n",
        "            output = model(mel)\n",
        "            loss = criterion(output, label)\n",
        "            val_loss += loss.item() * mel.size(0)\n",
        "            preds.extend(torch.sigmoid(output).cpu().numpy())\n",
        "            targets.extend(label.cpu().numpy())\n",
        "            val_bar.set_postfix(loss=loss.item())\n",
        "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "    f1 = compute_f1(preds, targets)\n",
        "\n",
        "    print(f\"ğŸ“Š Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | F1-score: {f1:.4f}\")\n",
        "\n",
        "    # ğŸ“Œ ëª¨ë¸ ë§¤ epochë§ˆë‹¤ ì €ì¥\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'best_f1': best_f1\n",
        "    }, checkpoint_path)\n",
        "\n",
        "    # ğŸ“Œ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë„ ë³„ë„ë¡œ ì €ì¥\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        torch.save(model.state_dict(), os.path.join(base_path, 'deepvoice_best.pt'))\n",
        "        print(f\"âœ… ëª¨ë¸ ì €ì¥ë¨ (F1 ê°±ì‹ : {best_f1:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5. í•™ìŠµëœ ëª¨ë¸ í‰ê°€ ì¤€ë¹„\n",
        "# > ì‚¬ìš©ì ì •ì˜ í‰ê°€ìš© í”„ë¡œí† ì½œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "test_protocol_path = os.path.join(base_path, 'ASVspoof2019_LA_cm_protocols', 'custom_protocol_test.txt')\n",
        "\n",
        "test_df = pd.read_csv(\n",
        "    test_protocol_path,\n",
        "    sep='\\s+',\n",
        "    header=None,\n",
        "    names=['speaker_id', 'file_id', 'system_id', 'attack_type', 'label']\n",
        ")\n",
        "\n",
        "# ë¼ë²¨ ìˆ«ìë¡œ ë³€í™˜\n",
        "test_df['label_binary'] = test_df['label'].map({'bonafide': 0, 'spoof': 1})\n",
        "\n",
        "# flac íŒŒì¼ ê²½ë¡œ ê²€ìƒ‰\n",
        "test_df['file_path'] = test_df['file_id'].apply(find_flac_path)\n",
        "test_df = test_df[test_df['file_path'].notnull()]\n",
        "print(f\"ğŸ“ ìœ íš¨í•œ í‰ê°€ ë°ì´í„° ìˆ˜: {len(test_df)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpmk6jc4PVY-",
        "outputId": "37bd4cb2-f702-4a85-9b91-1745e3bdb7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ ìœ íš¨í•œ í‰ê°€ ë°ì´í„° ìˆ˜: 19324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í‰ê°€ìš© ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ Mel-spectrogram ë³€í™˜\n",
        "\n",
        "mel_list, label_list = [], []\n",
        "batch_size = 2000\n",
        "batch_idx = 0\n",
        "save_dir = '/content/drive/MyDrive/Deepvoice_Detection_Dataset/test_processed'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"ğŸ§ª test mel ìƒì„±\"):\n",
        "    try:\n",
        "        path = row['file_path']\n",
        "        label = row['label_binary']\n",
        "        waveform, _ = torchaudio.load(path)\n",
        "        mel = extract_mel_from_waveform(waveform)\n",
        "        mel_list.append(mel)\n",
        "        label_list.append(label)\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ {path}: {e}\")\n",
        "        continue\n",
        "\n",
        "    if len(mel_list) >= batch_size:\n",
        "        data_path = os.path.join(save_dir, f'test_data_batch_{batch_idx}.npy')\n",
        "        label_path = os.path.join(save_dir, f'test_labels_batch_{batch_idx}.npy')\n",
        "        np.save(data_path, np.stack(mel_list))\n",
        "        np.save(label_path, np.array(label_list))\n",
        "        mel_list, label_list = [], []\n",
        "        batch_idx += 1\n",
        "\n",
        "# ë§ˆì§€ë§‰ ë°°ì¹˜ ì €ì¥\n",
        "if mel_list:\n",
        "    data_path = os.path.join(save_dir, f'test_data_batch_{batch_idx}.npy')\n",
        "    label_path = os.path.join(save_dir, f'test_labels_batch_{batch_idx}.npy')\n",
        "    np.save(data_path, np.stack(mel_list))\n",
        "    np.save(label_path, np.array(label_list))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_56C7OxMPdFa",
        "outputId": "4feb37eb-7ec8-43c1-8136-4035d966d90d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ğŸ§ª test mel ìƒì„±: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19324/19324 [2:09:56<00:00,  2.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LazyMelDataSet í‰ê°€ìš©ìœ¼ë¡œ ë¡œë”©\n",
        "\n",
        "test_dataset = LazyMelDataset('/content/drive/MyDrive/Deepvoice_Detection_Dataset/test_processed', prefix='test')\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"ğŸ“¦ test dataset í¬ê¸°: {len(test_loader.dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZhAnD-fPkrK",
        "outputId": "46efcf00-c13d-4ea6-d7bb-07d1cd1eee50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ test dataset í¬ê¸°: 19324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6. í•™ìŠµëœ ëª¨ë¸ í‰ê°€\n",
        "\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "model = DeepVoiceDetector().to(device)\n",
        "model.load_state_dict(torch.load(os.path.join(base_path, 'deepvoice_best.pt'), map_location=device))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for mel, label in tqdm(test_loader, desc=\"ğŸ§ª Test Evaluation\"):\n",
        "      mel, label = mel.to(device), label.to(device)\n",
        "      output = model(mel)\n",
        "      probs = torch.sigmoid(output)\n",
        "      all_preds.extend(probs.cpu().numpy())\n",
        "      all_labels.extend(label.cpu().numpy())\n",
        "\n",
        "# numpy ë³€í™˜\n",
        "true_labels = np.array(all_labels)\n",
        "pred_probs = np.array(all_preds)\n",
        "pred_binary = (pred_probs > 0.5).astype(int)\n",
        "\n",
        "# ğŸ§ª 0. ìƒ˜í”Œì´ ì—†ì„ ê²½ìš° ì¢…ë£Œ\n",
        "if len(true_labels) == 0:\n",
        "    print(\"âŒ í‰ê°€í•  ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "else:\n",
        "    # 1. ë¶„í¬ ì¶œë ¥\n",
        "    print(\"âœ… ê³ ìœ  ì˜ˆì¸¡ ë¼ë²¨:\", np.unique(pred_binary, return_counts=True))\n",
        "    print(\"âœ… ê³ ìœ  ì‹¤ì œ ë¼ë²¨:\", np.unique(true_labels, return_counts=True))\n",
        "\n",
        "    # 2. classification_report ì¶œë ¥ (zero_division=0ìœ¼ë¡œ ê²½ê³  ì–µì œ)\n",
        "    print(\"\\nğŸ“‹ Classification Report\")\n",
        "    print(classification_report(true_labels, pred_binary,\n",
        "                                target_names=['bonafide', 'spoof'],\n",
        "                                labels=[0, 1],\n",
        "                                zero_division=0))\n",
        "\n",
        "    # 3. ì¶”ê°€ ì§€í‘œ ì¶œë ¥\n",
        "    try:\n",
        "        f1 = f1_score(true_labels, pred_binary, zero_division=0)\n",
        "        roc_auc = roc_auc_score(true_labels, pred_probs)\n",
        "        print(f\"ğŸ¯ F1-score: {f1:.4f}\")\n",
        "        print(f\"ğŸ“ˆ ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "        # 4. Confusion Matrix ì¶œë ¥ ë° ì‹œê°í™”\n",
        "        cm = confusion_matrix(true_labels, pred_binary, labels=[0, 1])\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['bonafide', 'spoof'])\n",
        "\n",
        "        print(\"\\nğŸ“Š Confusion Matrix:\")\n",
        "        print(cm)\n",
        "\n",
        "        disp.plot(cmap='Blues')\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.grid(False)\n",
        "        plt.show()\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"â— ROC-AUC ê³„ì‚° ì‹¤íŒ¨: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        },
        "id": "rrywDNzuP_E2",
        "outputId": "0ddfc3bf-bf0c-4f7c-edf4-da6e440453e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN output shape: torch.Size([1, 128, 50, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ğŸ§ª Test Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 604/604 [16:24<00:00,  1.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ê³ ìœ  ì˜ˆì¸¡ ë¼ë²¨: (array([0, 1]), array([ 1950, 17374]))\n",
            "âœ… ê³ ìœ  ì‹¤ì œ ë¼ë²¨: (array([0., 1.], dtype=float32), array([ 1987, 17337]))\n",
            "\n",
            "ğŸ“‹ Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    bonafide       1.00      0.98      0.99      1987\n",
            "       spoof       1.00      1.00      1.00     17337\n",
            "\n",
            "    accuracy                           1.00     19324\n",
            "   macro avg       1.00      0.99      0.99     19324\n",
            "weighted avg       1.00      1.00      1.00     19324\n",
            "\n",
            "ğŸ¯ F1-score: 0.9989\n",
            "ğŸ“ˆ ROC-AUC: 0.9997\n",
            "\n",
            "ğŸ“Š Confusion Matrix:\n",
            "[[ 1949    38]\n",
            " [    1 17336]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}